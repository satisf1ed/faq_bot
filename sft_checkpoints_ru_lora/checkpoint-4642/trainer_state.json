{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.9995962423622513,
  "eval_steps": 500,
  "global_step": 4642,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.043067481359855726,
      "grad_norm": 0.4355641007423401,
      "learning_rate": 4.8933649289099524e-05,
      "loss": 1.714,
      "step": 100
    },
    {
      "epoch": 0.08613496271971145,
      "grad_norm": 0.2845219671726227,
      "learning_rate": 4.785652735889703e-05,
      "loss": 1.4963,
      "step": 200
    },
    {
      "epoch": 0.12920244407956716,
      "grad_norm": 0.253559947013855,
      "learning_rate": 4.677940542869453e-05,
      "loss": 1.4783,
      "step": 300
    },
    {
      "epoch": 0.1722699254394229,
      "grad_norm": 0.27818697690963745,
      "learning_rate": 4.570228349849203e-05,
      "loss": 1.4739,
      "step": 400
    },
    {
      "epoch": 0.21533740679927862,
      "grad_norm": 0.26131024956703186,
      "learning_rate": 4.462516156828953e-05,
      "loss": 1.4759,
      "step": 500
    },
    {
      "epoch": 0.2584048881591343,
      "grad_norm": 0.2784360349178314,
      "learning_rate": 4.354803963808703e-05,
      "loss": 1.4737,
      "step": 600
    },
    {
      "epoch": 0.3014723695189901,
      "grad_norm": 0.2722996771335602,
      "learning_rate": 4.2470917707884536e-05,
      "loss": 1.4681,
      "step": 700
    },
    {
      "epoch": 0.3445398508788458,
      "grad_norm": 0.2675812542438507,
      "learning_rate": 4.139379577768204e-05,
      "loss": 1.4673,
      "step": 800
    },
    {
      "epoch": 0.38760733223870153,
      "grad_norm": 0.28905946016311646,
      "learning_rate": 4.0316673847479536e-05,
      "loss": 1.46,
      "step": 900
    },
    {
      "epoch": 0.43067481359855725,
      "grad_norm": 0.3039586842060089,
      "learning_rate": 3.923955191727704e-05,
      "loss": 1.4613,
      "step": 1000
    },
    {
      "epoch": 0.47374229495841297,
      "grad_norm": 0.2791086435317993,
      "learning_rate": 3.8162429987074536e-05,
      "loss": 1.4579,
      "step": 1100
    },
    {
      "epoch": 0.5168097763182686,
      "grad_norm": 0.3123435378074646,
      "learning_rate": 3.708530805687204e-05,
      "loss": 1.4561,
      "step": 1200
    },
    {
      "epoch": 0.5598772576781245,
      "grad_norm": 0.31158798933029175,
      "learning_rate": 3.600818612666954e-05,
      "loss": 1.4525,
      "step": 1300
    },
    {
      "epoch": 0.6029447390379802,
      "grad_norm": 0.296552836894989,
      "learning_rate": 3.493106419646704e-05,
      "loss": 1.459,
      "step": 1400
    },
    {
      "epoch": 0.6460122203978359,
      "grad_norm": 0.28119462728500366,
      "learning_rate": 3.385394226626454e-05,
      "loss": 1.4631,
      "step": 1500
    },
    {
      "epoch": 0.6890797017576916,
      "grad_norm": 0.31130462884902954,
      "learning_rate": 3.277682033606204e-05,
      "loss": 1.4558,
      "step": 1600
    },
    {
      "epoch": 0.7321471831175473,
      "grad_norm": 0.3171467185020447,
      "learning_rate": 3.169969840585955e-05,
      "loss": 1.4511,
      "step": 1700
    },
    {
      "epoch": 0.7752146644774031,
      "grad_norm": 0.3037596046924591,
      "learning_rate": 3.0622576475657045e-05,
      "loss": 1.4599,
      "step": 1800
    },
    {
      "epoch": 0.8182821458372588,
      "grad_norm": 0.3092840611934662,
      "learning_rate": 2.954545454545455e-05,
      "loss": 1.4594,
      "step": 1900
    },
    {
      "epoch": 0.8613496271971145,
      "grad_norm": 0.33373042941093445,
      "learning_rate": 2.8468332615252048e-05,
      "loss": 1.4587,
      "step": 2000
    },
    {
      "epoch": 0.9044171085569702,
      "grad_norm": 0.30464065074920654,
      "learning_rate": 2.739121068504955e-05,
      "loss": 1.4522,
      "step": 2100
    },
    {
      "epoch": 0.9474845899168259,
      "grad_norm": 0.338110089302063,
      "learning_rate": 2.6314088754847048e-05,
      "loss": 1.4568,
      "step": 2200
    },
    {
      "epoch": 0.9905520712766817,
      "grad_norm": 0.3211740553379059,
      "learning_rate": 2.5236966824644555e-05,
      "loss": 1.4606,
      "step": 2300
    },
    {
      "epoch": 1.034023310274286,
      "grad_norm": 0.3209068179130554,
      "learning_rate": 2.415984489444205e-05,
      "loss": 1.4676,
      "step": 2400
    },
    {
      "epoch": 1.0770907916341417,
      "grad_norm": 0.32470911741256714,
      "learning_rate": 2.3082722964239554e-05,
      "loss": 1.448,
      "step": 2500
    },
    {
      "epoch": 1.1201582729939974,
      "grad_norm": 0.3282315135002136,
      "learning_rate": 2.2005601034037054e-05,
      "loss": 1.4396,
      "step": 2600
    },
    {
      "epoch": 1.1632257543538531,
      "grad_norm": 0.31702667474746704,
      "learning_rate": 2.0928479103834554e-05,
      "loss": 1.4465,
      "step": 2700
    },
    {
      "epoch": 1.2062932357137088,
      "grad_norm": 0.33075377345085144,
      "learning_rate": 1.9851357173632057e-05,
      "loss": 1.4447,
      "step": 2800
    },
    {
      "epoch": 1.2493607170735646,
      "grad_norm": 0.33430424332618713,
      "learning_rate": 1.8774235243429557e-05,
      "loss": 1.4521,
      "step": 2900
    },
    {
      "epoch": 1.2924281984334205,
      "grad_norm": 0.3357447683811188,
      "learning_rate": 1.769711331322706e-05,
      "loss": 1.4555,
      "step": 3000
    },
    {
      "epoch": 1.3354956797932762,
      "grad_norm": 0.34432798624038696,
      "learning_rate": 1.6619991383024557e-05,
      "loss": 1.4542,
      "step": 3100
    },
    {
      "epoch": 1.378563161153132,
      "grad_norm": 0.39298298954963684,
      "learning_rate": 1.554286945282206e-05,
      "loss": 1.4479,
      "step": 3200
    },
    {
      "epoch": 1.4216306425129877,
      "grad_norm": 0.31543827056884766,
      "learning_rate": 1.446574752261956e-05,
      "loss": 1.4488,
      "step": 3300
    },
    {
      "epoch": 1.4646981238728434,
      "grad_norm": 0.3176669478416443,
      "learning_rate": 1.3388625592417062e-05,
      "loss": 1.448,
      "step": 3400
    },
    {
      "epoch": 1.507765605232699,
      "grad_norm": 0.3531355857849121,
      "learning_rate": 1.2311503662214563e-05,
      "loss": 1.4469,
      "step": 3500
    },
    {
      "epoch": 1.5508330865925548,
      "grad_norm": 0.31820064783096313,
      "learning_rate": 1.1234381732012065e-05,
      "loss": 1.4525,
      "step": 3600
    },
    {
      "epoch": 1.5939005679524105,
      "grad_norm": 0.3277111053466797,
      "learning_rate": 1.0157259801809565e-05,
      "loss": 1.4431,
      "step": 3700
    },
    {
      "epoch": 1.6369680493122662,
      "grad_norm": 0.33981892466545105,
      "learning_rate": 9.080137871607066e-06,
      "loss": 1.4445,
      "step": 3800
    },
    {
      "epoch": 1.680035530672122,
      "grad_norm": 0.3372415006160736,
      "learning_rate": 8.003015941404568e-06,
      "loss": 1.4457,
      "step": 3900
    },
    {
      "epoch": 1.7231030120319777,
      "grad_norm": 0.33910518884658813,
      "learning_rate": 6.925894011202068e-06,
      "loss": 1.4482,
      "step": 4000
    },
    {
      "epoch": 1.7661704933918334,
      "grad_norm": 0.3763352632522583,
      "learning_rate": 5.848772080999569e-06,
      "loss": 1.4475,
      "step": 4100
    },
    {
      "epoch": 1.8092379747516891,
      "grad_norm": 0.3433409333229065,
      "learning_rate": 4.77165015079707e-06,
      "loss": 1.4494,
      "step": 4200
    },
    {
      "epoch": 1.8523054561115448,
      "grad_norm": 0.34541502594947815,
      "learning_rate": 3.6945282205945716e-06,
      "loss": 1.4471,
      "step": 4300
    },
    {
      "epoch": 1.8953729374714006,
      "grad_norm": 0.32390740513801575,
      "learning_rate": 2.6174062903920724e-06,
      "loss": 1.4444,
      "step": 4400
    },
    {
      "epoch": 1.9384404188312563,
      "grad_norm": 0.35568803548812866,
      "learning_rate": 1.5402843601895735e-06,
      "loss": 1.4466,
      "step": 4500
    },
    {
      "epoch": 1.981507900191112,
      "grad_norm": 0.3389895558357239,
      "learning_rate": 4.6316242998707454e-07,
      "loss": 1.4437,
      "step": 4600
    }
  ],
  "logging_steps": 100,
  "max_steps": 4642,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.985540076166185e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
